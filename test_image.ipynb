{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "import skimage\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils\n",
    "from tensorflow.python.platform import gfile\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path1 = 'test_pics/qc-01.jpg'\n",
    "##  360  480 \n",
    "\n",
    "path2 = 'test_pics/qingcai-01.jpg'\n",
    "path3 = 'test_pics/jmc-02.jpg'\n",
    "\n",
    "vege_dict = {0:'jmc', 1:'qc', 2:'qingcai'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_height_width(img_path):\n",
    "    \"\"\"读取图片，分别返回图片的宽和高\"\"\"\n",
    "    img_arr = io.imread(img_path)\n",
    "    return [len(img_arr) , len(img_arr[1])]\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"根据图片路径读取图片，先进行居中切割，再转为float型，后缩放为224\"\"\"\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "#     img = img / 255.0\n",
    "#     assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(img, (224, 224))\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def get_binstr_by_resized_img(binstr, cache_path='./cache_pic/', ):\n",
    "    \"\"\"解码binstr得到图片，并将其本地缓存，再读取该数据, 返回为数组\"\"\"\n",
    "    \n",
    "    img = Image.open(BytesIO(base64.b64decode(binstr)))\n",
    "    \n",
    "    local_time = time.strftime(\"%Y-%m-%d  %H_%M_%S\",time.localtime(time.time()))\n",
    "    save_path = cache_path + local_time + '.jpg'\n",
    "    img.save(save_path, 'JPEG')\n",
    "    \n",
    "    resized_img = load_image(save_path)\n",
    "    \n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height_wid = get_image_height_width(path1)\n",
    "print ('The origin image shape : ',height_wid)\n",
    "\n",
    "\n",
    "fn = open(path1, 'rb')\n",
    "picdata =  fn.read()\n",
    "binstr = base64.b64encode(picdata)\n",
    "# image = get_image_by_binbyte(binstr, 360, 480)\n",
    "\n",
    "\n",
    "ss = get_binstr_by_resized_img(binstr)\n",
    "print (ss)\n",
    "\n",
    "\n",
    "\n",
    "bstr0 = base64.b64decode(binstr)\n",
    "\n",
    "arr0 = np.array(bytearray(bstr0))\n",
    "# print ('length of arr0', len(arr0))\n",
    "# print (arr0)\n",
    "\n",
    "##  使用该方法对编码后的\n",
    "im = Image.open(BytesIO(base64.b64decode(binstr)))\n",
    "resutl = im.save('accept.jpg', 'JPEG')  ##对照片做本地缓存\n",
    "\n",
    "# print(im)\n",
    "\n",
    "height_wid = get_image_height_width('accept.jpg')\n",
    "print ('The origin image shape : ',height_wid)\n",
    "\n",
    "# bstr1 = base64.b64encode(np.array2string(arr0.tostring()))\n",
    "# bstr2 = base64.b64decode(bstr1)\n",
    "# arr2 = np.array(bytearray(bstr2))\n",
    "\n",
    "# print ('length of arr2', len(arr2))\n",
    "\n",
    "# tple = struct.unpack( '4f', my_data )\n",
    "# my_array = np.array( tple, dtype=np.float32 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f =  open(path1, 'rb')\n",
    "picData = f.read()\n",
    "#     print(id(picData))\n",
    "\n",
    "bb64 = base64.b64encode(picData)\n",
    "\n",
    "# with open('./image_code', 'wb+') as f:\n",
    "#     f.write(bb64)\n",
    "#     print ('图片二进制字节码已保存到：', '/image_code')\n",
    "\n",
    "# with open('./image_code', 'rb') as f1:\n",
    "#     binstr = f1.read()\n",
    "#     print ('已读取二进制字节码')\n",
    "# print (bb64)\n",
    "\n",
    "    \n",
    "pic1_ori = base64.b64decode(bb64)\n",
    "\n",
    "image = np.matrix(bytearray(pic1_ori))\n",
    "# image = get_image_by_binbyte(pic1_ori, 360 , 480)\n",
    "np.reshape(image, newshape=(360, 480))\n",
    "\n",
    "print (image)\n",
    "print (len(image))\n",
    "\n",
    "\n",
    "\n",
    "# print (batch1)\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_list = []\n",
    "\n",
    "batch1 = load_image(path1)\n",
    "batch2 = load_image(path2)\n",
    "\n",
    "batch_list.append(batch1.reshape((1, 224, 224, 3)))\n",
    "batch_list.append(batch2.reshape((1, 224, 224, 3)))\n",
    "test_images = np.concatenate(batch_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  读取pb文件，在默认的graph图中做以下操作：\n",
    "1. 使用vgg16模型对图像进行特征值提取\n",
    "2. 读取pb文件，恢复图结构(该图结构不包含瓶颈层)\n",
    "3. 将待测图片的特征值送入第二步恢复的图结构中，预测其类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    with tf.Session() as sess:\n",
    "        vgg = vgg16.Vgg16()\n",
    "\n",
    "        ###  定义input\n",
    "        input_test = tf.placeholder(tf.float32, shape=[None, 224, 224, 3], name='input_test')\n",
    "        ###  定义 图像处理后的特征值，\n",
    "        inputs_fea = tf.placeholder(tf.float32, shape=[None , 4096], name='inputs_fea')\n",
    "        \n",
    "        with tf.name_scope(\"content_vgg\"):\n",
    "            vgg.build(input_test)\n",
    "            feature_codes = sess.run(vgg.relu6, feed_dict={input_test:test_images})\n",
    "            print (feature_codes)\n",
    "    #             print (\"feature_codes.shape\" , feature_codes.shape)\n",
    "            assert feature_codes.shape == (2, 4096)\n",
    "        \n",
    "        \n",
    "        # 加入一个256维的全连接的层\n",
    "        fc = tf.contrib.layers.fully_connected(inputs_fea, 256)\n",
    "        logits = tf.contrib.layers.fully_connected(fc, 3, activation_fn=None)\n",
    "        predicted = tf.nn.softmax(logits, name='predicted')\n",
    "\n",
    "        \n",
    "        ###  创建saver对象时，必须要定义图结构，如上面的fc logits  predicted \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"checkpoints/zsy.ckpt\")  # 注意这里只恢复变量值\n",
    "        ## 需指定要恢复的操作符或张量， 读取到对应的graph对象中\n",
    "        \n",
    "#         g = tf.get_default_graph()\n",
    "#         g.get_tensor_by_name('predicted:0')\n",
    "        prob_op = g.get_operation_by_name('predicted')\n",
    "        pred_result = sess.run(predicted, feed_dict={inputs_fea : feature_codes})\n",
    "        print (pred_result)\n",
    "        result_list = tf.argmax(pred_result , 1 ).eval()\n",
    "        print (result_list)\n",
    "        print (type(result_list))\n",
    "        for v in result_list:\n",
    "            print (vege_dict[v])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  下面代码是用pb文件保存已训练模型权重，还有bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default() as g:\n",
    "#     with tf.Session() as sess:\n",
    "        \n",
    "# #         sess.run(tf.global_variables_initializer())\n",
    "#         vgg = vgg16.Vgg16()\n",
    "        \n",
    "#         ###  定义input\n",
    "#         input_test = tf.placeholder(tf.float32, shape=[None, 224, 224, 3], name='input_test')\n",
    "#         ###  定义 图像处理后的特征值，\n",
    "#         inputs_fea = tf.placeholder(tf.float32, shape=[None , 4096], name='inputs_fea')\n",
    "        \n",
    "\n",
    "#         with tf.name_scope(\"content_vgg\"):\n",
    "#         # 载入VGG16模型\n",
    "#             vgg.build(input_test)\n",
    "#             feature_codes = sess.run(vgg.relu6, feed_dict={input_test:test_images})\n",
    "#             print (feature_codes)\n",
    "#     #             print (\"feature_codes.shape\" , feature_codes.shape)\n",
    "#             assert feature_codes.shape == (2, 4096)\n",
    "\n",
    "#         print('input_test.graph =   {0}'.format(input_test.graph))\n",
    "\n",
    "#         ###   读取pb文件，读取对应张量\n",
    "# #         output_graph_def = tf.GraphDef()\n",
    "# #         with open('checkpoints/zsy.pb', \"rb\") as f:\n",
    "# #             output_graph_def.ParseFromString(f.read())\n",
    "# #             _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "\n",
    "#         ###   \n",
    "#         with gfile.FastGFile('checkpoints/zsy.pb', 'rb') as f:\n",
    "#             graph_def = tf.GraphDef()\n",
    "#             graph_def.ParseFromString(f.read())\n",
    "\n",
    "# #             sess.graph.as_default()\n",
    "# #             predicted = tf.import_graph_def(graph_def, return_elements=['predicted:0'])\n",
    "#             fc = tf.contrib.layers.fully_connected(inputs_fea, 256)\n",
    "#             logits = tf.contrib.layers.fully_connected(fc, 3, activation_fn=None)\n",
    "#             predicted = tf.nn.softmax(logits, name='predicted')\n",
    "\n",
    "# #             inputs_fea = sess.graph.get_tensor_by_name('inputs_fea:0')\n",
    "#             predicted = sess.graph.get_operation_by_name('predicted')\n",
    "\n",
    "\n",
    "# #             sess.run(predicted, feed_dict={feature_test: np.reshape(batch1, [-1, 224, 224, 3])})  feature_codes\n",
    "#             result = sess.run(predicted, feed_dict={inputs_fea: feature_codes})\n",
    "#             print (result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  格式化输出当前日期，时间的两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##  方法一\n",
    "# import time\n",
    "# time_int = time.time()\n",
    "# local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()))\n",
    "# print (type(time.time()), time.time())\n",
    "# print (type(local_time), local_time)\n",
    "\n",
    "# ##  方法二\n",
    "# import datetime\n",
    "# local_time = datetime.datetime.now()\n",
    "# print (type(local_time), local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "url = \"http://www.lance.cn/myweb/request\"\n",
    "headers = {'content-type': 'application/json'}\n",
    "requestData = {\"name\": \"lance\", \"age\": \"28\"}\n",
    "ret = requests.post(url, json=requestData, headers=headers)\n",
    "if ret.status_code == 200:\n",
    "    text = json.loads(ret.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 客户端访问api 端口服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "URL = 'http://192.168.30.110:5001/recognize_vege'\n",
    "requestData = {}\n",
    "\n",
    "test_path = './test_pics/qingcai-03.jpg'\n",
    "\n",
    "with open(test_path, 'rb') as f:\n",
    "    picData = f.read()\n",
    "    bb64 = base64.b64encode(picData)\n",
    "    requestData['pic_str'] = bb64\n",
    "\n",
    "#     print (requestData)\n",
    "result = requests.post(URL, json=requestData, headers=headers)\n",
    "if result.status_code == 200:\n",
    "#     text = json.loads(result.text)\n",
    "    print (result.test)\n",
    "#     print( test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  返回top1的概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_prob(prob, file_path):\n",
    "    synset = [l.strip() for l in open(file_path).readlines()]\n",
    "\n",
    "    # print prob\n",
    "    pred = np.argsort(prob)[::-1]\n",
    "\n",
    "    # Get top1 label\n",
    "    top1 = synset[pred[0]]\n",
    "    print((\"Top1: \", top1, prob[pred[0]]))\n",
    "    # Get top5 label\n",
    "    top5 = [(synset[pred[i]], prob[pred[i]]) for i in range(5)]\n",
    "    print((\"Top5: \", top5))\n",
    "    return top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  测试阶段\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    data = []\n",
    "    #  从mete元文件恢复graph结构\n",
    "    saver = tf.train.import_meta_graph('checkpoints/zsy.ckpt.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    chkp.print_tensors_in_checkpoint_file(\"checkpoints/zsy.ckpt\", tensor_name='', all_tensors=True)\n",
    "#     print( graph.eval())\n",
    "    \n",
    "    \n",
    "    inputs_ = graph.get_tensor_by_name(\"inputs_:0\")\n",
    "    feed_dict = {x: data}\n",
    "    \n",
    "    logits = graph.get_tensor_by_name('logits_eval:0')  # labels_\n",
    "    \n",
    "    classification_result = sess.run(logits, feed_dict)\n",
    "    \n",
    "    # 打印出预测矩阵\n",
    "    print (classification_result)\n",
    "    # 打印出预测矩阵每一行最大值的索引\n",
    "    print (tf.argmax(classification_result, 1).eval())\n",
    "    # 根据索引通过字典对应样本类别\n",
    "    \n",
    "    output = []\n",
    "    output = tf.argmax(classification_result, 1).eval()\n",
    "    \n",
    "    for i in range(len(output)):\n",
    "        print (\"第\", i+1, \"张蔬菜预测：\" + vege_dict[output[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
